{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05f8a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd, \n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    MeanEnsembled,\n",
    "    Activationsd\n",
    ")\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from monai.inferers import SimpleInferer, SlidingWindowInferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36c7eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") \n",
    "\n",
    "UNet_meatdata = dict(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd23aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/scratch/scratch6/akansh12/Parse_data/train/train/\"\n",
    "train_images = sorted(glob.glob(os.path.join(root_dir, \"*\", 'image', \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(root_dir, \"*\", 'label', \"*.nii.gz\")))\n",
    "\n",
    "data_dicts = [{\"image\": images_name, \"label\": label_name} for images_name, label_name in zip(train_images, train_labels)]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "set_determinism(seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4298ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:34<00:00,  3.80s/it]\n"
     ]
    }
   ],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-1000, a_max=1000,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_ds = CacheDataset(\n",
    "    data = val_files, transform = val_transforms,\n",
    "    cache_rate = 1.0, num_workers = 4\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size = 1, shuffle = False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbb2632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "from monai.metrics import DiceMetric\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "944dfe84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = UNet(**UNet_meatdata).to(device)\n",
    "path2weights = \"/scratch/scratch6/akansh12/challenges/parse2022/temp/selected_models/unet_1000_hu_160_0853.pth\"\n",
    "state_dict = torch.load(path2weights, map_location='cpu')\n",
    "for keyA, keyB in zip(state_dict, model_1.state_dict()):\n",
    "    state_dict = OrderedDict((keyB if k == keyA else k, v) for k, v in state_dict.items())\n",
    "model_1.load_state_dict(state_dict)\n",
    "\n",
    "model_2 = UNet(**UNet_meatdata).to(device)\n",
    "path2weights = \"/scratch/scratch6/akansh12/challenges/parse2022/temp/selected_models/unet_1000_hu_160_8550.pth\"\n",
    "state_dict = torch.load(path2weights, map_location='cpu')\n",
    "for keyA, keyB in zip(state_dict, model_2.state_dict()):\n",
    "    state_dict = OrderedDict((keyB if k == keyA else k, v) for k, v in state_dict.items())\n",
    "model_2.load_state_dict(state_dict)\n",
    "\n",
    "model_3 = UNet(**UNet_meatdata).to(device)\n",
    "path2weights = \"/scratch/scratch6/akansh12/challenges/parse2022/temp/selected_models/unet_1000_hu_160_w_augmentations_8551.pth\"\n",
    "state_dict = torch.load(path2weights, map_location='cpu')\n",
    "for keyA, keyB in zip(state_dict, model_3.state_dict()):\n",
    "    state_dict = OrderedDict((keyB if k == keyA else k, v) for k, v in state_dict.items())\n",
    "model_3.load_state_dict(state_dict)\n",
    "\n",
    "##More-data-models\n",
    "model_4 = UNet(**UNet_meatdata).to(device)\n",
    "path2weights = \"/scratch/scratch6/akansh12/challenges/parse2022/temp/selected_models/unet_1000_hu_160_w_augmentations_more_data_8838.pth\"\n",
    "state_dict = torch.load(path2weights, map_location='cpu')\n",
    "for keyA, keyB in zip(state_dict, model_4.state_dict()):\n",
    "    state_dict = OrderedDict((keyB if k == keyA else k, v) for k, v in state_dict.items())\n",
    "model_4.load_state_dict(state_dict)\n",
    "\n",
    "model_5 = UNet(**UNet_meatdata).to(device)\n",
    "path2weights = \"/scratch/scratch6/akansh12/challenges/parse2022/temp/selected_models/unet_1000_hu_160_w_augmentations_more_data_focal_8860.pth\"\n",
    "state_dict = torch.load(path2weights, map_location='cpu')\n",
    "for keyA, keyB in zip(state_dict, model_5.state_dict()):\n",
    "    state_dict = OrderedDict((keyB if k == keyA else k, v) for k, v in state_dict.items())\n",
    "model_5.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14ca8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2968973",
   "metadata": {},
   "source": [
    "### Ensemble max voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8596fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d7a6ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddf23a026e64e4d9aab139c82c9b433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c4b33d8d434d05a0f39c1b6b06302d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9033]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b94926612f476684158098804810a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8959]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65726670438c4a0ab463668c864ee4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7872]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d902b5d2711426d9f689a4a63b97602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8136]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b69785e57446a39ef6966361b49dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7729]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93629fb80e944d09ba9e28d0d5c729f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8838]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9209adf01c5478f96a7eac89277b4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9096]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d76e7a65f3477a8e3fac01444e1fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8726]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e907785a4614fba9c87b7b4e2ce0d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8696]])\n",
      "0.8564942479133606\n"
     ]
    }
   ],
   "source": [
    "metric_values = []\n",
    "with torch.no_grad():\n",
    "    for index, val_data in enumerate(tqdm(val_loader)):\n",
    "\n",
    "        val_inputs, val_labels = val_data['image'].to(device), val_data['label'].to(device)\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 8\n",
    "        val_output = 0\n",
    "        \n",
    "        for mod in tqdm(models):\n",
    "            mod.eval()\n",
    "            val_output_ = sliding_window_inference(\n",
    "                            val_inputs, roi_size, sw_batch_size, mod)\n",
    "            val_output_ = [post_pred(i) for i in decollate_batch(val_output_)]\n",
    "\n",
    "            val_output = val_output + val_output_[0]\n",
    "\n",
    "        val_output = [(val_output/len(models))>0.5]\n",
    "        val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "        print(dice_metric(y_pred=val_output, y=val_labels))\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7481f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e820cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values = []\n",
    "with torch.no_grad():\n",
    "    for index, val_data in enumerate(tqdm(val_loader)):\n",
    "\n",
    "        val_inputs, val_labels = val_data['image'].to(device), val_data['label'].to(device)\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 8\n",
    "        val_output_ = sliding_window_inference(\n",
    "                            val_inputs, roi_size, sw_batch_size, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in tqdm(models):\n",
    "            mod.eval()\n",
    "            val_output_ = sliding_window_inference(\n",
    "                            val_inputs, roi_size, sw_batch_size, mod)\n",
    "            val_output_ = [post_pred(i) for i in decollate_batch(val_output_)]\n",
    "\n",
    "            val_output = val_output + val_output_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff93b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
