{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f538ab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Project-MONAI/MONAI#egg.gitmonai@0.8.1+271.g07de215c\n",
      "  Cloning https://github.com/Project-MONAI/MONAI to /tmp/pip-req-build-7qf145dx\n",
      "  Running command git clone -q https://github.com/Project-MONAI/MONAI /tmp/pip-req-build-7qf145dx\n",
      "  Resolved https://github.com/Project-MONAI/MONAI to commit df4a7d72e1d231b898f88d92cf981721c49ceaeb\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /scratch/scratch6/akansh12/env/lib/python3.7/site-packages (from monai==0.9.0rc2+17.gdf4a7d7) (1.20.3)\n",
      "Requirement already satisfied: torch>=1.7 in /scratch/scratch6/akansh12/env/lib/python3.7/site-packages (from monai==0.9.0rc2+17.gdf4a7d7) (1.10.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /scratch/scratch6/akansh12/env/lib/python3.7/site-packages (from torch>=1.7->monai==0.9.0rc2+17.gdf4a7d7) (4.0.0)\n",
      "Building wheels for collected packages: monai\n",
      "  Building wheel for monai (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for monai: filename=monai-0.9.0rc2+17.gdf4a7d7-py3-none-any.whl size=939726 sha256=d912326b555caa6752b8f4b91db12b59bb8535554bc9398e2df6c74bd7c4ed10\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wy58v117/wheels/f2/c0/99/f8569609371aedbe1d13deb5d47a146054ec096943f779e5a3\n",
      "Successfully built monai\n",
      "Installing collected packages: monai\n",
      "  Attempting uninstall: monai\n",
      "    Found existing installation: monai 0.8.1\n",
      "    Uninstalling monai-0.8.1:\n",
      "      Successfully uninstalled monai-0.8.1\n",
      "Successfully installed monai-0.9.0rc2+17.gdf4a7d7\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/scratch/scratch6/akansh12/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting nibabel==3.1.1\n",
      "  Downloading nibabel-3.1.1-py3-none-any.whl (3.3 MB)\n",
      "     |████████████████████████████████| 3.3 MB 1.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /scratch/scratch6/akansh12/env/lib/python3.7/site-packages (from nibabel==3.1.1) (21.2)\n",
      "Requirement already satisfied: numpy>=1.13 in /scratch/scratch6/akansh12/env/lib/python3.7/site-packages (from nibabel==3.1.1) (1.20.3)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /scratch/scratch6/akansh12/env/lib/python3.7/site-packages (from packaging>=14.3->nibabel==3.1.1) (2.4.7)\n",
      "Installing collected packages: nibabel\n",
      "  Attempting uninstall: nibabel\n",
      "    Found existing installation: nibabel 3.2.2\n",
      "    Uninstalling nibabel-3.2.2:\n",
      "      Successfully uninstalled nibabel-3.2.2\n",
      "Successfully installed nibabel-3.1.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/scratch/scratch6/akansh12/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tqdm==4.63.0\n",
      "  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "     |████████████████████████████████| 76 kB 967 kB/s             \n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.3\n",
      "    Uninstalling tqdm-4.62.3:\n",
      "      Successfully uninstalled tqdm-4.62.3\n",
      "Successfully installed tqdm-4.63.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/scratch/scratch6/akansh12/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Project-MONAI/MONAI#egg.gitmonai@0.8.1+271.g07de215c \n",
    "!pip install nibabel==3.1.1\n",
    "!pip install tqdm==4.63.0\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9afd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SwinUNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d956b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/scratch/scratch6/akansh12/Parse_data/train/train/\"\n",
    "train_images = sorted(glob.glob(os.path.join(root_dir, \"*\", 'image', \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(root_dir, \"*\", 'label', \"*.nii.gz\")))\n",
    "\n",
    "data_dicts = [{\"image\": images_name, \"label\": label_name} for images_name, label_name in zip(train_images, train_labels)]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e1512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-700,\n",
    "            a_max=300,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-700, a_max=300, b_min=0.0, b_max=1.0, clip=True\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34fb223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:52<00:00,  2.17s/it]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:26<00:00,  4.40s/it]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(\n",
    "    data=train_files,\n",
    "    transform=train_transforms,\n",
    "    cache_num=24,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=8,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=1, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_transforms, cache_num=6, cache_rate=1.0, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9bc238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SwinUNETR(\n",
    "    img_size=(96, 96, 96),\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb78b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c69a9b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained self-supervied Swin UNETR backbone weights !\n"
     ]
    }
   ],
   "source": [
    "#Channge this while training in GPU\n",
    "weight = torch.load(\"/scratch/scratch6/akansh12/challenges/parse2022/temp/model_swinvit.pt\", map_location=torch.device('cpu'))\n",
    "model.load_from(weights=weight)\n",
    "print(\"Using pretrained self-supervied Swin UNETR backbone weights !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f23e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f46e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(epoch_iterator_val):\n",
    "            val_inputs, val_labels = (batch[\"image\"].to(device), batch[\"label\"].to(device))\n",
    "            val_outputs = sliding_window_inference(val_inputs, (96, 96, 96), 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [\n",
    "                post_label(val_label_tensor) for val_label_tensor in val_labels_list\n",
    "            ]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [\n",
    "                post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list\n",
    "            ]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            epoch_iterator_val.set_description(\n",
    "                \"Validate (%d / %d Steps)\" % (global_step, 10.0)\n",
    "            )\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(\n",
    "        train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True\n",
    "    )\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"].to(device), batch[\"label\"].to(device))\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\"\n",
    "            % (global_step, max_iterations, loss)\n",
    "        )\n",
    "        if (\n",
    "            global_step % eval_num == 0 and global_step != 0\n",
    "        ) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(\n",
    "                val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True\n",
    "            )\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(\n",
    "                    model.state_dict(), os.path.join(root_dir, \"/scratch/scratch6/akansh12/challenges/parse2022/temp/best_metric_model.pth\")\n",
    "                )\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "        global_step += 1\n",
    "        \n",
    "    return global_step, dice_val_best, global_step_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29177855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (X / X Steps) (loss=X.X):   0%|                                                                                                                             | 0/91 [00:00<?, ?it/s]/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Training (0 / 30000 Steps) (loss=1.38593):   1%|█▏                                                                                                         | 1/91 [01:22<2:03:02, 82.02s/it]Process Process-2:\n",
      "Process Process-4:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Process Process-7:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "Traceback (most recent call last):\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/tools/anaconda3/envs/torch37/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 30000\n",
    "eval_num = 500\n",
    "post_label = AsDiscrete(to_onehot=2)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=2)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(\n",
    "        global_step, train_loader, dice_val_best, global_step_best\n",
    "    )\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"/scratch/scratch6/akansh12/challenges/parse2022/temp/best_metric_model.pth\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f28122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455f12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
