{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc83e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ResNetUNet\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c418797",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Preparation\n",
    "\n",
    "model = ResNetUNet()\n",
    "model.base_model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.layer0[0] = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.conv_original_size0[0] = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93e10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a120a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f0a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_img_to_label_path(path):\n",
    "    parts = list(path.parts)\n",
    "    parts[parts.index(\"image\")] = \"label\"  \n",
    "    return Path(*parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a73cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/scratch/scratch6/akansh12/Parse_data/processed_train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "675499ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.CenterCrop(224,224),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p = 0.2),\n",
    "    A.RandomRotate90(p=0.1),\n",
    "    A.Rotate((-30,30), p = 0.5),\n",
    "        ])\n",
    "test_transforms = A.Compose([\n",
    "    A.CenterCrop(224,224),\n",
    "    A.Rotate(0, p = 1)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "980b98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseDataset(Dataset):\n",
    "    def __init__(self, img_dir,data_type = 'train', transform = None):\n",
    "        if data_type == 'train':\n",
    "            self.img_dir = list(img_dir.glob(\"*train/*/image/*.npy\"))\n",
    "        if data_type == 'val':\n",
    "            self.img_dir = list(img_dir.glob(\"*val/*/image/*.npy\"))\n",
    "            \n",
    "        self.img_dir.sort()\n",
    "        self.transforms = transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_dir)\n",
    "    def __getitem__(self,idx):\n",
    "        img = np.load(self.img_dir[idx]).astype(\"float32\")\n",
    "        mask = np.load(change_img_to_label_path(self.img_dir[idx]))\n",
    "        mask = np.clip(mask, 0, 1).astype(\"float32\")\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        return  torch.tensor(img).unsqueeze(0), torch.FloatTensor(mask).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12b0eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ParseDataset(img_dir = data_path, transform = train_transforms)\n",
    "val_data = ParseDataset(img_dir = data_path,data_type = 'val', transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d4feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_data:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f9ab6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=0)\n",
    "val_dl = DataLoader(val_data, batch_size=32, shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e506aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 224, 224]) torch.float32\n",
      "torch.Size([64, 1, 224, 224]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for img_b, mask_b in train_dl:\n",
    "    print(img_b.shape,img_b.dtype)\n",
    "    print(mask_b.shape, mask_b.dtype)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4a843d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79d865cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef_metric(inputs, target, eps=1e-7):\n",
    "    intersection = (target * inputs).sum()\n",
    "    union = (target.sum() + inputs.sum()) - intersection + eps\n",
    "\n",
    "    if target.sum() == 0 and inputs.sum() == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return (intersection + eps) / union\n",
    "\n",
    "def dice_coef_metric(inputs, target):\n",
    "    intersection = 2.0 * (target * inputs).sum()\n",
    "    union = target.sum() + inputs.sum()\n",
    "    if target.sum() == 0 and inputs.sum() == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "## Loss\n",
    "\n",
    "def dice_coef_loss(inputs, target):\n",
    "    smooth = 1.0\n",
    "    intersection = 2.0 * ((target * inputs).sum()) + smooth\n",
    "    union = target.sum() + inputs.sum() + smooth\n",
    "\n",
    "    return 1 - (intersection / union)\n",
    "\n",
    "\n",
    "def bce_dice_loss(inputs, target):\n",
    "    dicescore = dice_coef_loss(inputs, target)\n",
    "    bcescore = nn.BCELoss()\n",
    "    bceloss = bcescore(inputs, target)\n",
    "\n",
    "    return bceloss + dicescore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd35847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, lr_scheduler, metric,\n",
    "                    dataloader, epoch, criterion=bce_dice_loss):\n",
    "    \n",
    "    print(\"Start Train ...\")\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    accur = []\n",
    "\n",
    "    for data, target in tqdm(dataloader):\n",
    "\n",
    "        data = data.to(DEVICE).float()\n",
    "        targets = target.to(DEVICE)\n",
    "\n",
    "        outputs = model(data)\n",
    "\n",
    "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
    "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
    "\n",
    "        train_dice = metric(out_cut, targets.data.cpu().numpy())\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accur.append(train_dice)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    lr = lr_scheduler.get_last_lr()[0]\n",
    "    print(\"Epoch [%d]\" % (epoch),\n",
    "          \"Mean loss on train:\", np.array(losses).mean(), \n",
    "          \"Mean DICE on train:\", np.array(accur).mean(), \n",
    "          \"Learning Rate:\", lr)\n",
    "\n",
    "    \n",
    "    return np.array(losses).mean(), np.array(accur).mean(), lr\n",
    "\n",
    "\n",
    "def val_epoch(model, metric, dataloader, epoch, threshold=0.5):\n",
    "    \n",
    "    print(\"Start Validation ...\")\n",
    "    model.eval()\n",
    "    \n",
    "    val_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in tqdm(dataloader):\n",
    "\n",
    "            data = data.to(DEVICE).float()\n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
    "            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n",
    "            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n",
    "\n",
    "            val_dice = metric(out_cut, targets.data.cpu().numpy())\n",
    "            val_acc.append(val_dice)\n",
    "\n",
    "        print(\"Epoch:  \" + str(epoch) + \"  Threshold:  \" + str(threshold)\\\n",
    "              + \" Mean Validation DICE Score:\", np.array(val_acc).mean())\n",
    "        \n",
    "        return  np.array(val_acc).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "163ed561",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "stage_epoch =  [12, 8, 15] #[12, 8, 5]\n",
    "stage_optimizer = [\n",
    "    torch.optim.Adamax(params, lr=0.0002),\n",
    "    torch.optim.SGD(params, lr=0.00009, momentum=0.9),\n",
    "    torch.optim.Adam(params, lr=0.00005),\n",
    "]\n",
    "\n",
    "stage_scheduler = [\n",
    "    torch.optim.lr_scheduler.CosineAnnealingLR(stage_optimizer[0], 4, 1e-6),\n",
    "    torch.optim.lr_scheduler.CyclicLR(stage_optimizer[1], base_lr=1e-5, max_lr=2e-4),\n",
    "    torch.optim.lr_scheduler.CosineAnnealingLR(stage_optimizer[2], 4, 1e-6),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81b405d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cff656f81b4985a203f363c5749138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28704/1725695599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         loss, train_dice, lr = train_one_epoch(model, optimizer, lr_scheduler, \n\u001b[0;32m---> 17\u001b[0;31m                                                dice_coef_metric, train_dl, epoch)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mval_dice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice_coef_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_28704/2318092650.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, lr_scheduler, metric, dataloader, epoch, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mout_cut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/challenges/parse2022/notebooks/2D_seg/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_up3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/scratch6/akansh12/env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DEVICE = device\n",
    "weights_dir = \"/scratch/scratch6/akansh12/challenges/parse2022/temp/weights\"\n",
    "if os.path.exists(weights_dir) == False:\n",
    "    os.mkdir(weights_dir)\n",
    "\n",
    "\n",
    "loss_history = []\n",
    "train_dice_history = []\n",
    "val_dice_history = []\n",
    "lr_history = []\n",
    "\n",
    "for k, (num_epochs, optimizer, lr_scheduler) in enumerate(zip(stage_epoch, stage_optimizer, stage_scheduler)):\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        \n",
    "        loss, train_dice, lr = train_one_epoch(model, optimizer, lr_scheduler, \n",
    "                                               dice_coef_metric, train_dl, epoch)\n",
    "    \n",
    "        val_dice = val_epoch(model, dice_coef_metric, val_dl, epoch)\n",
    "        \n",
    "        \n",
    "        # train history\n",
    "        loss_history.append(loss)\n",
    "        train_dice_history.append(train_dice)\n",
    "        lr_history.append(lr)\n",
    "        val_dice_history.append(val_dice)\n",
    "\n",
    "        # save best weights\n",
    "        best_dice = max(val_dice_history)\n",
    "        if val_dice >= best_dice:\n",
    "            torch.save({'state_dict': model.state_dict()},\n",
    "                        os.path.join(weights_dir, f\"{val_dice:0.6f}_.pth\"))\n",
    "    \n",
    "    print(\"\\nNext stage\\n\")\n",
    "    # Load the best weights\n",
    "    best_weights =  sorted(glob.glob(weights_dir + \"/*\"),\n",
    "                       key= lambda x: x[8:-5])[-1]\n",
    "    checkpoint = torch.load(best_weights)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    print(f'Loaded model: {best_weights.split(\"/\")[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b5ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95547c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71cd778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b8274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35f387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f5ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34550c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(np.load(list(train_path.glob(\"train/*/image/*.npy\"))[0]), cmap = \"bone\")\n",
    "plt.imshow(np.load(change_img_to_label_path(list(train_path.glob(\"train/*/image/*.npy\"))[0])), alpha = 0.4,cmap = \"bone\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
